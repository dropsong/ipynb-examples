{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c682d879",
   "metadata": {},
   "source": [
    "# 原理部分\n",
    "\n",
    "## ID3 和 C4.5\n",
    "\n",
    "之前在 [人工智能导论](https://dropsong.github.io/posts/6f3f8819.html) 中 ID3 决策树算法信息增益的方法有一个问题：\n",
    "\n",
    "在图片 80-26 中，可以看到 ``信息增益 = 信息熵 - 条件熵``，这里的条件熵在计算的时候，会乘以一个系数（特征取值数的倒数）。这样在实践中，会造成**偏向特征取值数较多的特征**。\n",
    "\n",
    "为了解决这个问题，C4.5 算法提出了**信息增益比最大**的原则。\n",
    "\n",
    "ID3 决策树：\n",
    "\n",
    "$$\n",
    "Gain(D, a) = Ent(D) - \\sum_{i}^{k} p_i \\cdot Ent(D | i)\n",
    "$$\n",
    "\n",
    "C4.5 决策树提出了信息增益率：\n",
    "\n",
    "$$\n",
    "GainRatio(D, a) = \\frac{Gain(D, a)}{Ent(a)}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "| 名称  |  分支方式   | 备注                                                                 |\n",
    "|-------|------------|----------------------------------------------------------------------|\n",
    "| ID3   | 信息增益   | ID3只能对离散属性的数据集构造决策树                                   |\n",
    "| C4.5  | 信息增益率 | 优化后解决了ID3分支过程中总喜欢偏向取值较多的属性                       |\n",
    "| CART  | Gini系数   | 可以进行分类和回归，可以处理离散属性，也可以处理连续的               |\n",
    "\n",
    "有益的补充：\n",
    "- [决策树（上）——ID3、C4.5、CART（非常详细）](https://zhuanlan.zhihu.com/p/85731206)，该内容已备份为 pdf，在该 ipynb 文件的 github 仓库同级目录下。\n",
    "- [决策树--信息增益，信息增益比，Geni指数的理解](https://www.cnblogs.com/muzixi/p/6566803.html)，该文章已在 [archive.org](https://archive.org/) 中备份。\n",
    "\n",
    "一些更具体的细节可以参考 [《统计学习方法(李航)》](https://github.com/qqqil/books/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%E2%97%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E2%97%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95(%E6%9D%8E%E8%88%AA).pdf) 。\n",
    "\n",
    "ID3 的缺点：\n",
    "- ID3 没有剪枝策略，容易过拟合；\n",
    "- 信息增益准则对可取值数目较多的特征有所偏好，类似“编号”的特征其信息增益接近于 1；\n",
    "- 只能用于处理离散分布的特征；\n",
    "- 没有考虑缺失值。\n",
    "\n",
    "C4.5 相对于 ID3 的缺点对应有以下改进方式：\n",
    "- 引入悲观剪枝策略进行后剪枝；\n",
    "- 引入信息增益率作为划分标准；\n",
    "- 将连续特征离散化，假设 n 个样本的连续特征 A 有 m 个取值，C4.5 将其排序并取相邻两样本值的平均数共 m-1 个划分点，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点；\n",
    "- 对于缺失值的处理可以分为两个子问题：\n",
    "- 问题一：在特征值缺失的情况下进行划分特征的选择？（即如何计算特征的信息增益率）\n",
    "- 问题二：选定该划分特征，对于缺失该特征值的样本如何处理？（即到底把这个样本划分到哪个结点里）\n",
    "- 针对问题一，C4.5 的做法是：对于具有缺失值特征，用没有缺失的样本子集所占比重来折算；\n",
    "- 针对问题二，C4.5 的做法是：将样本同时划分到所有子节点，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。\n",
    "\n",
    "C4.5 的缺点：\n",
    "- 剪枝策略可以再优化；\n",
    "- C4.5 用的是多叉树，用二叉树效率更高；\n",
    "- C4.5 只能用于分类；\n",
    "- C4.5 使用的熵模型拥有大量耗时的对数运算，连续值还有排序运算；\n",
    "- C4.5 在构造树的过程中，对数值属性值需要按照其大小进行排序，从中选择一个分割点，所以只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时，程序无法运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be720c",
   "metadata": {},
   "source": [
    "## CART 算法流程\n",
    "\n",
    "CART(Classification and Regression Tree) 决策树使用\"基尼指数\" (Gini index)来选择划分属性。\n",
    "\n",
    "基尼值 Gini（D）：从数据集 D 中随机抽取两个样本，其类别标记不一致的概率。故，**Gini（D）值越小，数据集 D 的纯度越高**。\n",
    "\n",
    "数据集 D 的纯度可用基尼值来度量:\n",
    "\n",
    "$$\n",
    "Gini(D) = \\sum_{k=1}^{|y|} \\sum_{k' \\ne k} p_k p_{k'} = 1 - \\sum_{k=1}^{|y|} p_k^2\n",
    "$$\n",
    "\n",
    "基尼指数 Gini_index(D)：一般选择使划分后基尼系数最小的属性作为最优化分属性。\n",
    "\n",
    "$$\n",
    "GiniIndex(D, a) = \\sum_{v=1}^V \\frac{D^v}{D} Gini(D^v)\n",
    "$$\n",
    "\n",
    "CART 的算法流程：\n",
    "\n",
    "```\n",
    "while(当前节点\"不纯\")：\n",
    "    1.遍历每个变量的每一种分割方式，找到最好的分割点\n",
    "    2.分割成两个节点N1和N2\n",
    "end while\n",
    "每个节点足够“纯”为止\n",
    "```\n",
    "\n",
    "案例，根据下图列表，按照基尼指数的划分依据，做出决策树。\n",
    "\n",
    "| 序号 | 是否有房 | 婚姻状况  | 年收入 | 是否拖欠贷款 |\n",
    "|----|------|-------|------|--------|\n",
    "| 1  | yes  | single| 125k | no     |\n",
    "| 2  | no   | married|100k | no     |\n",
    "| 3  | no   | single| 70k  | no     |\n",
    "| 4  | yes  | married|120k | no     |\n",
    "| 5  | no   | divorced|95k | yes    |\n",
    "| 6  | no   | married|60k  | no     |\n",
    "| 7  | yes  | divorced|220k | no     |\n",
    "| 8  | no   | single| 85k  | yes    |\n",
    "| 9  | no   | married|75k  | no     |\n",
    "| 10 | No   | Single |90k  | Yes    |\n",
    "\n",
    "整理：\n",
    "\n",
    "![pic1](./1.png)\n",
    "\n",
    "step 1，对数据集非序列标号属性 ``{是否有房，婚姻状况，年收入}`` 分别计算它们的 Gini 指数，取 Gini 指数最小的属性作为决策树的根节点属性。\n",
    "\n",
    "> 第一次大循环\n",
    "\n",
    "step 2，根节点的Gini值为：\n",
    "\n",
    "$$\n",
    "Gini(\\text{是否拖欠贷款}) = 1 - (\\frac{3}{10})^2 - (\\frac{7}{10})^2 = 0.42\n",
    "$$\n",
    "\n",
    "step 3，当根据是否有房来进行划分时，Gini指数计算过程为：\n",
    "\n",
    "$$\n",
    "Gini(左子节点) = 1 - (\\frac{0}{3})^2 - (\\frac{3}{3})^2 = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "Gini(右子节点) = 1 - (\\frac{3}{7})^2 - (\\frac{4}{7})^2 = 0.4898\n",
    "$$\n",
    "\n",
    "$$\n",
    "GiniIndex(D, \\text{是否有房}) = \\frac{7}{10} \\cdot 0.4898 + \\frac{3}{10} \\cdot 0 = 0.343\n",
    "$$\n",
    "\n",
    "![pic2](./2.png)\n",
    "\n",
    "![pic3](./3.png)\n",
    "\n",
    "![pic4](./4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a89ed",
   "metadata": {},
   "source": [
    "# sklearn 决策树 API\n",
    "\n",
    "```python\n",
    "class sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0, monotonic_cst=None)\n",
    "```\n",
    "\n",
    "参考官网：\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "criterion : ``{“gini”, “entropy”, “log_loss”}, default=”gini”``\n",
    "- The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “log_loss” and “entropy” both for the Shannon information gain, see [Mathematical formulation](https://scikit-learn.org/stable/modules/tree.html#tree-mathematical-formulation).\n",
    "- 可以是 id3, 或者 c4.5\n",
    "\n",
    "max_depth: 树的深度大小。\n",
    "\n",
    "random_state: 随机数种子。\n",
    "\n",
    "min_samples_split, int 或 float，默认为 2 .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74733b2",
   "metadata": {},
   "source": [
    "# 决策树实例\n",
    "\n",
    "接下来我们**举一个例子，泰坦尼克号数据**。\n",
    "\n",
    "这个数据集描述泰坦尼克号上的个别乘客的生存状态。数据集的特征是票的类别，存活，乘坐班，年龄，登陆，home.dest，房间，票，船和性别等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d327c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Artun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1310</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Maprieder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1311</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zenn, Mr Philip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1312</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zievens, Rene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1313</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row.names pclass  survived  \\\n",
       "0             1    1st         1   \n",
       "1             2    1st         0   \n",
       "2             3    1st         0   \n",
       "3             4    1st         0   \n",
       "4             5    1st         1   \n",
       "...         ...    ...       ...   \n",
       "1308       1309    3rd         0   \n",
       "1309       1310    3rd         0   \n",
       "1310       1311    3rd         0   \n",
       "1311       1312    3rd         0   \n",
       "1312       1313    3rd         0   \n",
       "\n",
       "                                                 name      age     embarked  \\\n",
       "0                        Allen, Miss Elisabeth Walton  29.0000  Southampton   \n",
       "1                         Allison, Miss Helen Loraine   2.0000  Southampton   \n",
       "2                 Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   \n",
       "3     Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   \n",
       "4                       Allison, Master Hudson Trevor   0.9167  Southampton   \n",
       "...                                               ...      ...          ...   \n",
       "1308                               Zakarian, Mr Artun      NaN          NaN   \n",
       "1309                           Zakarian, Mr Maprieder      NaN          NaN   \n",
       "1310                                  Zenn, Mr Philip      NaN          NaN   \n",
       "1311                                    Zievens, Rene      NaN          NaN   \n",
       "1312                                   Zimmerman, Leo      NaN          NaN   \n",
       "\n",
       "                            home.dest room      ticket   boat     sex  \n",
       "0                        St Louis, MO  B-5  24160 L221      2  female  \n",
       "1     Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
       "2     Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male  \n",
       "3     Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
       "4     Montreal, PQ / Chesterville, ON  C22         NaN     11    male  \n",
       "...                               ...  ...         ...    ...     ...  \n",
       "1308                              NaN  NaN         NaN    NaN    male  \n",
       "1309                              NaN  NaN         NaN    NaN    male  \n",
       "1310                              NaN  NaN         NaN    NaN    male  \n",
       "1311                              NaN  NaN         NaN    NaN  female  \n",
       "1312                              NaN  NaN         NaN    NaN    male  \n",
       "\n",
       "[1313 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titan = pd.read_csv(\"./data/titanic.csv\")\n",
    "titan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6484b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   pclass  1313 non-null   object \n",
      " 1   age     633 non-null    float64\n",
      " 2   sex     1313 non-null   object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 30.9+ KB\n",
      "================\n",
      "     pclass      age     sex\n",
      "0       1st  29.0000  female\n",
      "1       1st   2.0000  female\n",
      "2       1st  30.0000    male\n",
      "3       1st  25.0000  female\n",
      "4       1st   0.9167    male\n",
      "...     ...      ...     ...\n",
      "1308    3rd      NaN    male\n",
      "1309    3rd      NaN    male\n",
      "1310    3rd      NaN    male\n",
      "1311    3rd      NaN  female\n",
      "1312    3rd      NaN    male\n",
      "\n",
      "[1313 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "x = titan[['pclass', 'age', 'sex']]\n",
    "y = titan['survived']\n",
    "\n",
    "x.info() # 看看有没有空值\n",
    "print('================')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bca7e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20326/4049615488.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  x['age'].fillna(x['age'].mean(), inplace=True) # 用均值填充\n",
      "/tmp/ipykernel_20326/4049615488.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x['age'].fillna(x['age'].mean(), inplace=True) # 用均值填充\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pclass        age     sex\n",
      "598    2nd  30.000000    male\n",
      "246    1st  62.000000    male\n",
      "905    3rd  31.194181  female\n",
      "300    1st  31.194181  female\n",
      "509    2nd  64.000000    male\n"
     ]
    }
   ],
   "source": [
    "# 缺失值处理\n",
    "x['age'].fillna(x['age'].mean(), inplace=True) # 用均值填充\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=4)\n",
    "print(x_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d953baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "=================\n",
      "['age' 'pclass=1st' 'pclass=2nd' 'pclass=3rd' 'sex=female' 'sex=male']\n",
      "[[30.          0.          1.          0.          0.          1.        ]\n",
      " [62.          1.          0.          0.          0.          1.        ]\n",
      " [31.19418104  0.          0.          1.          1.          0.        ]\n",
      " ...\n",
      " [34.          0.          1.          0.          0.          1.        ]\n",
      " [46.          1.          0.          0.          0.          1.        ]\n",
      " [31.19418104  0.          0.          1.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# 将非数值特征转换为 one-hot 编码\n",
    "dict = DictVectorizer(sparse=False)\n",
    "\n",
    "# to_dict 可以将 DataFrame 转换为字典列表\n",
    "x_train = dict.fit_transform(x_train.to_dict(orient='records'))\n",
    "\n",
    "print(type(x_train))\n",
    "print('=================')\n",
    "print(dict.get_feature_names_out())\n",
    "\n",
    "x_test = dict.transform(x_test.to_dict(orient='records'))\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6c6f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集里面有多少男的： 643.0\n",
      "训练集里面有多少女的： 341.0\n",
      "预测的准确率： 0.8085106382978723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec = DecisionTreeClassifier()  # 这是用于分类的决策树\n",
    "\n",
    "# 训练\n",
    "dec.fit(x_train, y_train)\n",
    "\n",
    "print('训练集里面有多少男的：', x_train[:, 5].sum())\n",
    "print('训练集里面有多少女的：', x_train[:, 4].sum())\n",
    "\n",
    "print('预测的准确率：', dec.score(x_test, y_test))\n",
    "\n",
    "# 导出决策树的结构\n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(dec, out_file=\"tree.dot\",\n",
    "                feature_names=dict.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9fb6f",
   "metadata": {},
   "source": [
    "这里会生成一个 ``tree.dot`` 文件，需要安装：\n",
    "\n",
    "```shell\n",
    "sudo apt install graphviz\n",
    "```\n",
    "\n",
    "然后执行命令：\n",
    "\n",
    "```shell\n",
    "dot -Tpng tree.dot -o tree.png\n",
    "```\n",
    "\n",
    "就得到下图：\n",
    "\n",
    "![tree.png](./tree.png)\n",
    "\n",
    "上图中，``value = [死亡， 存活]`` .\n",
    "\n",
    "观察发现，即使是走到叶子节点，是否存活也是不一定的。这是因为，**为了防止过拟合，进行了剪枝**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263bd50",
   "metadata": {},
   "source": [
    "# 剪枝\n",
    "\n",
    "## 为什么要剪枝\n",
    "\n",
    "![pic5](./5.png)\n",
    "\n",
    "随着树的增长，在训练样集上的精度是单调上升的，然而在独立的测试样例上测出的精度先上升后下降。\n",
    "\n",
    "出现这种情况的原因：\n",
    "- 噪声、样本冲突，即错误的样本数据。\n",
    "- 特征即属性不能完全作为分类标准。\n",
    "- 巧合的规律性，数据量不够大。\n",
    "\n",
    "## 常用的剪枝方法\n",
    "\n",
    "**预剪枝**：\n",
    "- 每一个结点所包含的最小样本数目，例如10，则该结点总样本数小于10时，则不再分；\n",
    "  - 参数 ``min_samples_split``\n",
    "- 指定树的高度或者深度，例如树的最大深度为4；\n",
    "- 指定结点的熵小于某个值，不再划分。随着树的增大，在训练样集上的精度是单调上升的，然而在独立的测试样例上测出的精度先上升后下降。\n",
    "\n",
    "**后剪枝**:\n",
    "在已生成的过拟合决策树上剪枝。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278959e0",
   "metadata": {},
   "source": [
    "# 集成学习方法-随机森林\n",
    "\n",
    "集成学习通过建立几个模型的组合来解决单一预测问题。它的工作原理是生成多个分类器/模型，各自独立地学习和作出预测。这些预测最后结合成单预测，因此优于任何一个单分类的做出预测。\n",
    "\n",
    "在机器学习中，**随机森林**是一个包含多个决策树的分类器，其输出的类别由个别树输出的类别的**众数**而定。\n",
    "\n",
    "例如，如果训练了 5 个树, 其中 4 个树结果是 True, 1 个树结果是 False, 那么最终结果是 True.\n",
    "\n",
    "随机森林的优点：\n",
    "- 在当前所有算法中，具有极好的准确率\n",
    "- 能够有效地运行在大数据集上\n",
    "- 能够处理具有高维特征的输入样本，而且不需要降维\n",
    "  - 参数 ``max_features=\"auto”``, 每个决策树的最大特征数量\n",
    "- 能够评估各个特征在分类问题上的重要性\n",
    "- 对于缺省值问题也能够获得很好得结果\n",
    "\n",
    "## 实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076c66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8389057750759878\n",
      "查看选择的参数： {'max_depth': 3, 'n_estimators': 80}\n",
      "选择的最好模型是： RandomForestClassifier(max_depth=3, n_estimators=80, n_jobs=-1)\n",
      "每个超参数每次交叉验证的结果： {'mean_fit_time': array([0.14392352, 0.24342028, 0.17605678, 0.24809376, 0.16642634,\n",
      "       0.23049982, 0.1252439 , 0.26372814, 0.17696961, 0.2391026 ,\n",
      "       0.12453755, 0.13311084]), 'std_fit_time': array([0.03557314, 0.01736664, 0.02824466, 0.01137561, 0.01475437,\n",
      "       0.01895239, 0.01013709, 0.07819231, 0.02562576, 0.03062173,\n",
      "       0.0305696 , 0.01633324]), 'mean_score_time': array([0.03291988, 0.05922087, 0.03991501, 0.05492504, 0.03968541,\n",
      "       0.04200427, 0.03020398, 0.0559086 , 0.04339806, 0.04944158,\n",
      "       0.03474371, 0.02569795]), 'std_score_time': array([0.0138835 , 0.00043513, 0.00693334, 0.0077229 , 0.00574088,\n",
      "       0.00651898, 0.01138553, 0.00132847, 0.00874411, 0.01721119,\n",
      "       0.01435718, 0.00102845]), 'param_max_depth': masked_array(data=[2, 2, 3, 3, 5, 5, 8, 8, 15, 15, 25, 25],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value=999999), 'param_n_estimators': masked_array(data=[50, 80, 50, 80, 50, 80, 50, 80, 50, 80, 50, 80],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value=999999), 'params': [{'max_depth': 2, 'n_estimators': 50}, {'max_depth': 2, 'n_estimators': 80}, {'max_depth': 3, 'n_estimators': 50}, {'max_depth': 3, 'n_estimators': 80}, {'max_depth': 5, 'n_estimators': 50}, {'max_depth': 5, 'n_estimators': 80}, {'max_depth': 8, 'n_estimators': 50}, {'max_depth': 8, 'n_estimators': 80}, {'max_depth': 15, 'n_estimators': 50}, {'max_depth': 15, 'n_estimators': 80}, {'max_depth': 25, 'n_estimators': 50}, {'max_depth': 25, 'n_estimators': 80}], 'split0_test_score': array([0.73780488, 0.73780488, 0.80487805, 0.80792683, 0.81097561,\n",
      "       0.81402439, 0.82012195, 0.81402439, 0.81402439, 0.81097561,\n",
      "       0.81097561, 0.81707317]), 'split1_test_score': array([0.82012195, 0.82012195, 0.82926829, 0.82317073, 0.82012195,\n",
      "       0.81707317, 0.82012195, 0.80792683, 0.81402439, 0.81402439,\n",
      "       0.81402439, 0.81707317]), 'split2_test_score': array([0.81707317, 0.81707317, 0.81402439, 0.82926829, 0.82317073,\n",
      "       0.82012195, 0.80487805, 0.81402439, 0.78963415, 0.79878049,\n",
      "       0.78658537, 0.79878049]), 'mean_test_score': array([0.79166667, 0.79166667, 0.81605691, 0.82012195, 0.81808943,\n",
      "       0.81707317, 0.81504065, 0.81199187, 0.80589431, 0.80792683,\n",
      "       0.80386179, 0.81097561]), 'std_test_score': array([0.03810637, 0.03810637, 0.01006046, 0.00897537, 0.00518193,\n",
      "       0.00248932, 0.00718604, 0.00287442, 0.01149767, 0.00658612,\n",
      "       0.01227952, 0.00862325]), 'rank_test_score': array([11, 11,  4,  1,  2,  3,  5,  6,  9,  8, 10,  7], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "# 随机森林进行预测（超参数调优）\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# n_jobs=-1 是使用所有的 CPU 核心\n",
    "rf = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "param = {\n",
    "    'n_estimators': [50, 80],\n",
    "    'max_depth': [2, 3, 5, 8, 15, 25]\n",
    "}\n",
    "\n",
    "gc = GridSearchCV(rf, param_grid = param, cv=3)\n",
    "\n",
    "gc.fit(x_train, y_train)\n",
    "\n",
    "print(\"准确率：\", gc.score(x_test, y_test))\n",
    "print(\"查看选择的参数：\", gc.best_params_)\n",
    "print(\"选择的最好模型是：\", gc.best_estimator_)\n",
    "print(\"每个超参数每次交叉验证的结果：\", gc.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e3f5d",
   "metadata": {},
   "source": [
    "## AIGC（有限验证）\n",
    "\n",
    "随机森林使用的是**有放回的抽样**（Bootstrap抽样）。具体来说：\n",
    "\n",
    "- 在训练每棵决策树时，随机森林会从原始训练数据集中**有放回地随机抽取样本**，生成一个与原始数据集大小相同的子集（称为Bootstrap样本）。\n",
    "- 由于是有放回的抽样，部分样本可能会被多次抽取，而部分样本可能不会被抽取到（大约有 1/3 的样本未被抽取，称为袋外样本，Out-of-Bag Samples）。\n",
    "- 每棵决策树只使用其对应的 Bootstrap 样本进行训练。\n",
    "\n",
    "这种有放回的抽样方式是随机森林的核心之一，它通过引入样本的随机性，增加了模型的多样性，从而提高了整体的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f7e6b",
   "metadata": {},
   "source": [
    "`n_estimators` 参数在 `RandomForestClassifier` 中**并不是指样本的数量**，而是指随机森林中**决策树的数量**。这是一个常见的**误解**。\n",
    "\n",
    "**解释**：\n",
    "1. **`n_estimators` 的定义**：\n",
    "   - 在 `sklearn.ensemble.RandomForestClassifier` 中，`n_estimators` 参数控制随机森林中包含的决策树的数量。\n",
    "   - 每棵决策树会独立训练，并通过集成（如投票或平均）来生成最终的预测结果。\n",
    "\n",
    "2. **样本的数量与决策树的关系**：\n",
    "   - 每棵决策树的训练数据是从原始训练集通过**有放回的抽样**（Bootstrap抽样）生成的。\n",
    "   - 样本的数量等于原始训练集的大小，但每棵树的样本是随机抽取的，且允许重复。\n",
    "\n",
    "3. **误解的来源**：\n",
    "   - 可能有人将 `n_estimators` 与样本数量混淆，因为每棵树的训练样本是从原始数据集中抽取的，但 `n_estimators` 实际上是控制森林中树的数量，而不是样本的数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc46b80f",
   "metadata": {},
   "source": [
    "在代码中：\n",
    "- `n_estimators` 候选值是 `50` 和 `80`，表示随机森林中分别包含 50 棵树或 80 棵树。\n",
    "- 这些树会独立训练，并通过集成方法（如投票）生成最终的预测结果。\n",
    "\n",
    "根据 [scikit-learn 官方文档](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)，`n_estimators` 的定义是：\n",
    "> The number of trees in the forest.\n",
    "\n",
    "因此，`n_estimators` 是决策树的数量，而不是样本的数量。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
